{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Performance\n",
    "- With sufficient capacity, a neural network model will often perform perfectly on training data, but it doesnt mean it will generalize well to new data\n",
    "## Sources of error\n",
    "- Noise:\n",
    "  - Stochastic element to data generating process\n",
    "  - Further exploratory variables that were not observed\n",
    "  - Inherent uncertainty in the true mapping from input to output\n",
    "- Bias:\n",
    "  - Model is not flexible enough to fit to the true function\n",
    "  - Systematic deviation of the model from the function we are modelling\n",
    "- Variance:\n",
    "  - Limited training examples, and there is no way of distinguishing systematic changes in the underlying function from the noise in the underlying data\n",
    "  - Uncertainty in the fitted model due to the particular training set we have\n",
    "\n",
    "\n",
    "$$ \\mathbb{E}_D[\\mathbb{E}_y[L[x]]] = \\mathbb{E}_D[(f[x,\\phi[D]] - f_{\\mu}[x])^2] + (f_{\\mu}[x] - \\mu_[x])^2 + \\sigma^{2} $$\n",
    "  - The expected loss after considering the uncertainty in the training data $D$ and the test data $y$ consists of three components\n",
    "    - $\\mathbb{E}_D[(f[x,\\phi[D]] - f_{\\mu}[x])^2]$ is the variance\n",
    "    - $(f_{\\mu}[x] - \\mu_[x])^2$ is the bias\n",
    "    - $\\sigma^2$ is the noise\n",
    "  - They combine linearly in linear regression with $MSE$, but their interaction can be more complex for other types of problems\n",
    "\n",
    "## Reducing error\n",
    "- Noise error is irreducible\n",
    "- Reducing variance\n",
    "  - Increasing quantity of data\n",
    "- Reducing bias\n",
    "  - Increasing model capacity\n",
    "- Bias-variance tradeoff\n",
    "  - For a fixed-size training dataset, the variance term increases as the model capacity increases\n",
    "- Overfitting\n",
    "  - Tries the model the noise in the data\n",
    "\n",
    "## Double descent\n",
    "- Test loss starts to increase when the model is fitting the training data perfectly, then starts to decrease again\n",
    "- Interaction of two phenomena\n",
    "  - Test performance becomes temporarily worse when the model has just enough capacity to memorize the data\n",
    "    - Exactly as predicted by the bias-variance trade-off\n",
    "  - Test performance continues to improve with capacity even after the training performance is perfect\n",
    "- After the model fits the training data perfectly, further capacity does not help the model. Any change must occur between the training points\n",
    "- *Inductive bias*\n",
    "  - Tendency of a model to prioritize one solution over another as it extrapolates between data points\n",
    "- As we add capacity to the model, it interpolates between the nearest points increasingly smoothly\n",
    "\n",
    "## Choosing hyperparameters\n",
    "- Chosen empirically\n",
    "- Measure their performance on a validation set\n",
    "- For every choice of hyperparameters, train the model with the training set and evaluate it on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curse of dimensionality\n",
    "- Two randomly sampled points from a standard normal distribution are close to ortogonal to each other\n",
    "- Distance from the origin of samples from a standard normal distribution is roughly constant\n",
    "- Most of the volume of a high-dimensional sphere is adjacent to its surface\n",
    "  - **Most of the volume of a highdimensional orange is in the peel, not the pulp**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-world performance\n",
    "- Data drift\n",
    "  - Statistics of real world data may change over time\n",
    "- Covariate shift\n",
    "  - Observing part of the function that wasnt seen during training\n",
    "- Concept shift\n",
    "  - Relationship between input and output may change over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
