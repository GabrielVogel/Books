{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "- Mainly for image data\n",
    "- Image data is high dimensional (224x244x3)\n",
    "- Nearby pixels are statistically correlated,but FCN have no notion of 'nearby' and treat the relation between every input equally\n",
    "- Interpretation of an image is estable under geometric transformations\n",
    "- Convolutional Neural Networks\n",
    "  - Process each local image region independently\n",
    "  - Fewer parameters than fully connected layers\n",
    "  - Exploit spatial relations between nearby pixels\n",
    "\n",
    "## Invariance and Equivariance\n",
    "- **Invariance**\n",
    "  - A function $f[x]$ of an image $x$ is invariant to a transformation $t[x]$ if $$f[t[x]] = f[x]$$\n",
    "  - The output of a function is the same regardless of $t[x]$\n",
    "- **Equivariance**\n",
    "  - A function $f[x]$ of an image $x$ is invariant to a transformation $t[x]$ if $$f[t[x]] = t[f[x]]$$\n",
    "  - Networks for pixel-to-pixel image segmentation should be equivariant to transformations like rotation,translation\n",
    "\n",
    "## Convolutional network for 1D inputs\n",
    "- CNNs consists of a series of convolutional layers, each of which is equivariant to translation\n",
    "- Pooling mechanisms that induce partial invariance to translation\n",
    "- Convolution\n",
    "  - Transforms an input vector $x$ to an output vector $z$ such that each output $z_i$ is a weighted sum of its nearby inputs\n",
    "  - Convolution kernel: Weights of the weighted sum. Used at every step\n",
    "  - Kernel size: Region which the inputs are weighted and summed\n",
    "  - *This is cross-correlation, but in machine learning its normally called correlation*\n",
    "- Padding\n",
    "  - How to deal with the first and last output in a kernel of size 3?\n",
    "  - Zero padding: Input is zero outside the range. Introduce extra information\n",
    "  - Treating the input as circular\n",
    "  - Discard the output positions where the kernel exceeds the range of input positions. Representation size decreases\n",
    "- Stride\n",
    "  - When evaluating the output at every position, stride = 1. If we have a stride of two, the outputs are decreased by roughly half\n",
    "- Kernel size \n",
    "  - Normally an odd number, so that can be centered in the current position\n",
    "  - Larger kernel sizes leads to more weights\n",
    "  - Increasing/Decreasing kernel size leads to the idea of dilated/atrous convolution\n",
    "    - Kernel of size 5 into a dilated kernel of size 3 with zeros at the second and fourth positions\n",
    "    - Number of $0$s is the dilation rate\n",
    "- Convolutional Layers\n",
    "  - Convolves the input, add the bias and pass through an activation function $a$\n",
    "  - With kernel size 3, stride one and dilation rate one, the $i^th$ hidden unit $h_i$ would be computed as $$h_i = [\\beta + w_1x_{i-1} + w_2x_{i} + w_3x_{i+1}]$$ $$ = a\\left[\\beta + \\sum_{j}^3 w_jx_{i+j-2}         \\right]$$\n",
    "  - Kernel weights $w$ and bias $\\beta$ are weighted parameters\n",
    "  - It's a special case of a fully connected network where $$h_{i} = a\\left[\\beta_i + \\sum_{j=1}^D w_{ij}x_j \\right]$$\n",
    "  - This fully connected layer would need\n",
    "    - $D^2$ weights and $D$ biases. Convolutional layer only uses three weights and one bias.\n",
    "    - Can reproduce if most weights are set to zero and the others are constrained to be identical\n",
    "- Channels\n",
    "  - Several convolutions in parallel\n",
    "  - Each convolution produces a set of hidden variables, termed *feature map* or *channel*\n",
    "  - If the incoming layers has $C_{i}$ channels and kernel size $K$, the resulting matrix will be $\\Omega \\in \\mathbb{R}^{C_i \\times K}$ and one bias\n",
    "  - If there are $C_o$ channels in the next layer, we need $\\Omega \\in \\mathbb{R}^{C_i \\times C_o \\times K}$ weights and $\\beta \\in \\mathbb{R}^{C_o}$ biases\n",
    "- CNNs and Receptive fields\n",
    "  - Receptive field\n",
    "    - Receptive field of a hidden unit is the region of the original input that feeds into it\n",
    "    - CNN with kernel size $3$\n",
    "      - Units in first layer takes a weighted sum of the three closest inputs $\\rightarrow$ Receptive field of size 3\n",
    "      - Units in second layer takes a weighted sum of the three closest positions in the first layer, which are weighted sums of size 3 $rightarrow$ Receptive field of size 5\n",
    "      - Receptive field of units in sucessive layers increases\n",
    "## CNNs for 2D input\n",
    "- Kernel is now a $2D$ object\n",
    "- A $3\\times3$ kernel applied to a $2D$ input comprising of elements $ij$ computes a single hidden output $h_{ij}$ as $$h_{ij} = a\\left[\\beta + \\sum_{m}^3\\sum_{n}^3 w_{mn}x_{i+m-2,j+n-2}    \\right]  $$\n",
    "- Weighted sum over a square $3\\times3$ matrix\n",
    "- Often the input is a RGB image, so the kernel would be $3\\times3\\times3$\n",
    "- With kernel size of $K \\times K$, $C_i$ output channels\n",
    "  - Each output is a weighted sum of $C_i\\times K \\times K$ quantities and a bias\n",
    "  - To compute $C_o$ output channels, it needs $C_i \\times C_o \\times K \\times K$ weights and $C_o$ biases\n",
    "## Downsampling/Upsampling\n",
    "- Downsampling\n",
    "  - Scaling down both dimensions by a factor of 2\n",
    "  - Maxpooling: Maximum value of 2x2 input values\n",
    "  - Mean pooling: Averaging the inputs \n",
    "  - Each approach to each channel individually\n",
    "- Upsampling\n",
    "  - Scale back up\n",
    "  - Duplicate all channels at each space position by four times\n",
    "  - Bilinear interpolation between input values\n",
    "\n",
    "## Applications\n",
    "- Image Classification\n",
    "  - Most methods reshape the image to a standard size (224x224 RGB)\n",
    "  - Famous architectures\n",
    "    - AlexNet\n",
    "    - VGG (more depth than AlexNet)\n",
    "- Object Detection\n",
    "  - Identify and localize multiple objects within an image\n",
    "  - YOLO (You Only Look Once)\n",
    "    - Output: Encodes which class is present at each of the 7x7 grid of locations\n",
    "    - For each location, output also encodes the bounding boxes\n",
    "      - Bounding boxes are defined by 5 parameters\n",
    "        - x and y position of the center\n",
    "        - height and width of the box\n",
    "        - confidence of the prediction\n",
    "- Semantic Segmentation\n",
    "  - Label to each pixel according to the object that it belongs to or no label if it doesnt match anything\n",
    "  - Input: 224x224 RGB image\n",
    "  - Output: 224x224x21 that contains the probability of each of the possible 21 classes in that pixel\n",
    "  - Encoder: Downsampling\n",
    "  - Decoder: Upsampling\n",
    "- **Increasing network depth indefinitely doesnt continue to help. After a certain depth, it becomes difficult to train. This is the motivation for *residual networks***"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
